import os
import requests
from dotenv import load_dotenv
from typing import List
import sys

# Add parent directory to path to import DataManager
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data_manager import DataManager

load_dotenv()
import json
import datetime
from collections import OrderedDict
sse_50_codes = [
    "600519.SHH",
    "601318.SHH",
    "600036.SHH",
    "601899.SHH",
    "600900.SHH",
    "601166.SHH",
    "600276.SHH",
    "600030.SHH",
    "603259.SHH",
    "688981.SHH",
    "688256.SHH",
    "601398.SHH",
    "688041.SHH",
    "601211.SHH",
    "601288.SHH",
    "601328.SHH",
    "688008.SHH",
    "600887.SHH",
    "600150.SHH",
    "601816.SHH",
    "601127.SHH",
    "600031.SHH",
    "688012.SHH",
    "603501.SHH",
    "601088.SHH",
    "600309.SHH",
    "601601.SHH",
    "601668.SHH",
    "603993.SHH",
    "601012.SHH",
    "601728.SHH",
    "600690.SHH",
    "600809.SHH",
    "600941.SHH",
    "600406.SHH",
    "601857.SHH",
    "601766.SHH",
    "601919.SHH",
    "600050.SHH",
    "600760.SHH",
    "601225.SHH",
    "600028.SHH",
    "601988.SHH",
    "688111.SHH",
    "601985.SHH",
    "601888.SHH",
    "601628.SHH",
    "601600.SHH",
    "601658.SHH",
    "600048.SHH"
]

def filter_data(data: dict,after_date: str):
    data_filtered = {}
    for date in data["Time Series (Daily)"]:
        date_obj = datetime.datetime.strptime(date, "%Y-%m-%d")
        after_date_obj = datetime.datetime.strptime(after_date, "%Y-%m-%d")
        if date_obj > after_date_obj:
            data_filtered[date] = data["Time Series (Daily)"][date]
    data["Time Series (Daily)"] = data_filtered
    return data

def merge_data(existing_data: dict, new_data: dict):
    """åˆå¹¶æ•°æ®ï¼šä¿ç•™å·²å­˜åœ¨çš„æ—¥æœŸï¼Œåªæ·»åŠ æ–°æ—¥æœŸ"""
    if existing_data is None or "Time Series (Daily)" not in existing_data:
        return new_data
    
    existing_dates = existing_data["Time Series (Daily)"]
    new_dates = new_data["Time Series (Daily)"]
    
    # åˆå¹¶ï¼šä¿ç•™å·²å­˜åœ¨çš„æ—¥æœŸï¼Œæ·»åŠ æ–°æ—¥æœŸ
    merged_dates = existing_dates.copy()
    for date in new_dates:
        if date not in merged_dates:
            merged_dates[date] = new_dates[date]
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆé™åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
    sorted_dates = OrderedDict(sorted(merged_dates.items(), key=lambda x: x[0], reverse=True))
    
    # æ›´æ–°æ•°æ®ï¼šä¿ç•™ existing_data çš„ Meta Dataï¼Œä½†æ›´æ–° Last Refreshed
    merged_data = existing_data.copy()
    merged_data["Time Series (Daily)"] = sorted_dates
    
    # æ›´æ–° Meta Data ä¸­çš„ Last Refreshedï¼ˆä½¿ç”¨æœ€æ–°çš„æ—¥æœŸï¼‰
    if sorted_dates:
        merged_data["Meta Data"]["3. Last Refreshed"] = list(sorted_dates.keys())[0]
    
    return merged_data

def load_existing_data(filepath: str):
    """åŠ è½½å·²å­˜åœ¨çš„æ•°æ®æ–‡ä»¶"""
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return None
    return None

def get_daily_price(SYMBOL: str, force_update: bool = False, verbose: bool = True):
    """
    è·å–Aè‚¡æ—¥ä»·æ ¼æ•°æ®ï¼Œæ”¯æŒæ™ºèƒ½ç¼“å­˜å’Œå¢é‡æ›´æ–°

    Args:
        SYMBOL: Aè‚¡ä»£ç 
        force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°ï¼Œå¿½ç•¥æœ¬åœ°æ•°æ®æ£€æŸ¥
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    data_manager = DataManager()

    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    os.makedirs("./A_stock_data", exist_ok=True)
    output_file = f"./A_stock_data/daily_prices_{SYMBOL}.json"

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ•°æ®
    if not data_manager.should_update_data(output_file, force_update):
        if verbose:
            summary = data_manager.get_update_summary(SYMBOL, output_file, False)
            print(summary)
        return

    # éœ€è¦æ›´æ–°æ•°æ®ï¼Œè°ƒç”¨API
    FUNCTION = "TIME_SERIES_DAILY"
    OUTPUTSIZE = "compact"
    APIKEY = os.getenv("ALPHAADVANTAGE_API_KEY")

    if not APIKEY:
        print(f"âŒ Error: ALPHAADVANTAGE_API_KEY not found in environment variables")
        return

    url = (
        f"https://www.alphavantage.co/query?function={FUNCTION}&symbol={SYMBOL}&entitlement=delayed&outputsize={OUTPUTSIZE}&apikey={APIKEY}"
    )

    try:
        if verbose:
            print(f"ğŸ“¡ Fetching data for {SYMBOL}...")

        r = requests.get(url, timeout=30)
        r.raise_for_status()
        data = r.json()

        # æ£€æŸ¥APIå“åº”ä¸­çš„é”™è¯¯ä¿¡æ¯
        if data.get("Note") is not None:
            if verbose:
                print(f"âš ï¸  {SYMBOL}: API call limit reached - {data.get('Note')}")
            return
        if data.get("Information") is not None:
            if verbose:
                print(f"âš ï¸  {SYMBOL}: API information - {data.get('Information')}")
            return
        if data.get("Error Message") is not None:
            if verbose:
                print(f"âŒ {SYMBOL}: API error - {data.get('Error Message')}")
            return

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
        if "Meta Data" not in data or "Time Series (Daily)" not in data:
            if verbose:
                print(f"âŒ {SYMBOL}: Invalid data structure received")
            return

        stock_name = data.get("Meta Data", {}).get("2. Symbol", SYMBOL)

        # è·å–æœ€æ–°æ—¥æœŸç”¨äºæ‘˜è¦
        latest_date = data_manager.get_latest_data_date(data)

        # è¿‡æ»¤æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if OUTPUTSIZE == "full":
            data = filter_data(data, "2025-10-01")

        # åˆå¹¶æ•°æ®ï¼šä¿ç•™å·²å­˜åœ¨çš„æ—¥æœŸï¼Œåªæ·»åŠ æ–°æ—¥æœŸ
        existing_data = data_manager.load_existing_data(output_file)
        merged_data = data_manager.merge_time_series_data(existing_data, data)

        # ä¿å­˜æ•°æ®
        data_manager.save_data(merged_data, output_file)

        if verbose:
            summary = data_manager.get_update_summary(SYMBOL, output_file, True, latest_date)
            print(summary)

        # ç‰¹æ®Šå¤„ç†ä¸Šè¯50æŒ‡æ•°
        if SYMBOL == "000016.SHH":
            handle_index_file(data_manager, data, verbose)

    except requests.exceptions.RequestException as e:
        if verbose:
            print(f"âŒ {SYMBOL}: Network error - {e}")
    except Exception as e:
        if verbose:
            print(f"âŒ {SYMBOL}: Unexpected error - {e}")


def handle_index_file(data_manager: DataManager, data: dict, verbose: bool = True):
    """å¤„ç†ä¸Šè¯50æŒ‡æ•°æ–‡ä»¶çš„ç‰¹æ®Šå¤„ç†"""
    try:
        # å¯¹äºä¸Šè¯50æŒ‡æ•°ï¼Œä¹Ÿéœ€è¦ä¿å­˜ Adaily_prices æ–‡ä»¶
        adaily_file = "./A_stock_data/Adaily_prices_000016.SHH.json"
        existing_adaily_data = data_manager.load_existing_data(adaily_file)
        adaily_data = data_manager.merge_time_series_data(existing_adaily_data, data)
        data_manager.save_data(adaily_data, adaily_file)

        # å¯¹äº index_daily_sse_50.jsonï¼Œä¹Ÿéœ€è¦åˆå¹¶
        index_file = "./A_stock_data/index_daily_sse_50.json"
        existing_index_data = data_manager.load_existing_data(index_file)
        index_data = data.copy()
        if "Meta Data" in index_data:
            index_data["Meta Data"]["2. Symbol"] = "000016.SH"
        index_data = data_manager.merge_time_series_data(existing_index_data, index_data)
        data_manager.save_data(index_data, index_file)

        if verbose:
            print("ğŸ“Š Updated SSE-50 index files")

    except Exception as e:
        if verbose:
            print(f"âš ï¸  Error handling index files: {e}")


def get_all_a_stock_prices(symbols: List[str] = None, force_update: bool = False, quiet: bool = False):
    """
    æ‰¹é‡è·å–Aè‚¡ä»·æ ¼æ•°æ®ï¼Œæ”¯æŒæ™ºèƒ½æ›´æ–°

    Args:
        symbols: Aè‚¡ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºSSE-50
        force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°æ‰€æœ‰æ•°æ®
        quiet: æ˜¯å¦é™é»˜è¿è¡Œ
    """
    if symbols is None:
        symbols = sse_50_codes

    data_manager = DataManager()

    if not quiet:
        print(f"ğŸš€ Starting A-stock price update for {len(symbols)} symbols...")
        print(f"ğŸ“… Trading day: {'Yes' if data_manager.is_trading_day() else 'No'}")
        print(f"ğŸ”„ Force update: {'Yes' if force_update else 'No'}")

    updated_count = 0
    skipped_count = 0
    error_count = 0

    for i, symbol in enumerate(symbols, 1):
        try:
            if not quiet:
                progress = f"[{i}/{len(symbols)}] "
                print(f"{progress}", end="")

            # è·å–æ–‡ä»¶è·¯å¾„
            output_file = f"./A_stock_data/daily_prices_{symbol}.json"

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            should_update = data_manager.should_update_data(output_file, force_update)

            if not should_update:
                skipped_count += 1
                if not quiet:
                    summary = data_manager.get_update_summary(symbol, output_file, False)
                    print(summary)
                continue

            # éœ€è¦æ›´æ–°ï¼Œè°ƒç”¨API
            get_daily_price(symbol, force_update, verbose=not quiet)
            updated_count += 1

            # APIè°ƒç”¨é—´éš”
            if i < len(symbols):
                import time
                time.sleep(12)  # Alpha Vantageå…è´¹ç‰ˆé¢‘ç‡é™åˆ¶

        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  Update interrupted by user at {symbol}")
            break
        except Exception as e:
            error_count += 1
            print(f"âŒ Error processing {symbol}: {e}")

    # æ˜¾ç¤ºæ€»ç»“
    if not quiet:
        print(f"\nğŸ“‹ A-Stock Update Summary:")
        print(f"   âœ… Updated: {updated_count}")
        print(f"   â­ï¸  Skipped: {skipped_count}")
        print(f"   âŒ Errors: {error_count}")
        print(f"   ğŸ“Š Total: {len(symbols)} symbols")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Update A-stock (SSE-50) price data with smart caching")
    parser.add_argument("--force", action="store_true", help="Force update all A-stocks")
    parser.add_argument("--quiet", action="store_true", help="Run in quiet mode")
    parser.add_argument("--symbols", nargs="+", help="Specific A-stock symbols to update")
    parser.add_argument("--list", action="store_true", help="List all available A-stock symbols")

    args = parser.parse_args()

    if args.list:
        print("Available SSE-50 A-stock symbols:")
        for i, symbol in enumerate(sse_50_codes, 1):
            print(f"{i:3d}. {symbol}")
        print(f"\nTotal: {len(sse_50_codes)} symbols")
    else:
        get_all_a_stock_prices(
            symbols=args.symbols,
            force_update=args.force,
            quiet=args.quiet
        )
